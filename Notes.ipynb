{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODULE 1 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Libraries ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " - Scientific Computing\n",
    "    - Pandas : Data Structures & Tools ~ Data manipulation & Analytics\n",
    "    - NumPy : Arrays & Matrices ~ all for data processing (can be used on obj\n",
    "    - SciPy : Integrals, Differentaial Equations, Optimization\n",
    "    \n",
    "- Visualization Libraries\n",
    "    - MatPlotLib : Plots and graphs\n",
    "    - Seaborn : plots: heatmaps, time series, violin plots)\n",
    "\n",
    "- Algorithmic Libraries (machine learning)\n",
    "    - scikit learn : statistical madeling, regression, classification, etc\n",
    "    - Statisical Models : explore data, estimate statistical models and perfrom tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Data Types                   | Pandas     | Python |\n",
    "|------------------------------|------------|--------|\n",
    "| numbers and strings          | object     | string |\n",
    "| numeric characters           |  int64     |   int  |\n",
    "| numeric characters w/decimal | float64    |  float |\n",
    "| time data                    | datetime64 | datetime module|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "url = file_path = \"automobile.csv\"\n",
    "\n",
    "df = pd.read_csv(url, header=None)\n",
    "\n",
    "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
    "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
    "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
    "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]\n",
    "\n",
    "df.columns = headers\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Data Frames ## \n",
    "\n",
    "- Missing  values\n",
    "    - replace it with the average/mode if possible\n",
    "    - drop the value/missing value;     df.dropna()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f['rawheader'] = df['rawheader'] +1\n",
    "\n",
    "df.dropna(subset = ['curb-weight'], axis=0)  #drop row\n",
    "\n",
    "#df.dropna(subset = ['curb-weight'], axis=1)  #drop column\n",
    "\n",
    "df.dropna(subset = ['curb-weight'], axis=0, inplace = True)  #inplace acts directly on data set\n",
    "\n",
    "#alternative to 'inplace'\n",
    "df[col].method(value, inplace=True)  #original \n",
    "\n",
    "#new\n",
    "df.method({col: value}, inplace=True)\n",
    "df[col] = df[col].method(value) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace with new value ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('missing_value', 'new_value')\n",
    "mean = df.mean({'col_name'})\n",
    "df.replace(np.nan, mean)\n",
    "\n",
    "#Replace missing data with frequency\n",
    "MostFrequentEntry = df['attribute_name'].value_counts().idxmax() \n",
    "df['attribute_name'].replace(np.nan,MostFrequentEntry\n",
    "df['attribute_name'].replace(np.nan,MostFrequentEntry, inplace=True))\n",
    "\n",
    "#Replace missing data with mean\n",
    "AverageValue=df['attribute_name'].astype('data_type').mean(axis=0)\n",
    "df['attribute_name'].replace(np.nan, AverageValue, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)  ##everything is type object... sad face\n",
    "# 'normalized-losses' column is missing a ton of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicate rows \n",
    "df = df.drop_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop un-needed columns\n",
    "df = df.drop(columns = 'aspiration')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove spaces and NaN values\n",
    "df['colname'].str.strip('.../,') #will remove / ' ' .\n",
    "df['colname'] = df['colname'].str.replace('[^a-zA-Z0-9]', '')  ## same affect, diff format\n",
    "                #cleaning phone numbers, remove everything that is not letter or number\n",
    "df['colname'] = df['colname'].apply(lambda x:x[0:3] + '-' + x[3:6] + '-' + x[6:10]) ## same output, using lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data Types ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#int(df['normalized-losses'])     #gives error message, cant convert obj/series/list to type int\n",
    "\n",
    "#replace NaN values with 0\n",
    "df['normalized-losses'] = df['normalized-losses'].replace(np.nan, 0)\n",
    "df['stroke'] = df['stroke'].replace(np.nan, 0.0)\n",
    "\n",
    "#convert column to int\n",
    "df['normalized-losses'] = pd.to_numeric(df['normalized-losses'], errors='coerce').astype('Int64')\n",
    "\n",
    "\n",
    "#df['symboling'] = pd.to_numeric(df['symboling'], errors='coerce').astype('Int64')\n",
    "#df['engine-size'] = pd.to_numeric(df['engine-size'], errors='coerce').astype('Int64')\n",
    "#df['horsepower'] = pd.to_numeric(df['horsepower'], errors='coerce').astype('Int64')\n",
    "#df['peak-rpm'] = pd.to_numeric(df['peak-rpm'], errors='coerce').astype('Int64')\n",
    "#df['city-mpg'] = pd.to_numeric(df['city-mpg'], errors='coerce').astype('Int64')\n",
    "#df['highway-mpg'] = pd.to_numeric(df['highway-mpg'], errors='coerce').astype('Int64')\n",
    "#df['price'] = pd.to_numeric(df['priceg'], errors='coerce').astype('Int64')\n",
    "\n",
    "\n",
    "#convert column to float\n",
    "#df['wheel-base'] = pd.to_numeric(df['wheel-base'], errors='coerce').astype('Int64').astype(float)\n",
    "for x in df['wheel-base']:\n",
    "    pd.to_numeric(df['wheel-base'].astype(np.float64))\n",
    "#df['wheel-base'] = df['wheel-base'].astype(float)\n",
    "#df['bore'] = pd.to_numeric(df['bore'], errors='coerce').astype('Int64')\n",
    "#df['stroke'] = pd.to_numeric(df['bore'], errors='coerce').astype('Int64')\n",
    "#df['compression-ratio'] = pd.to_numeric(df['compression-ratio'], errors='coerce').astype('Int64')\n",
    "#df.head(10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)\n",
    "#print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# replace missing values\n",
    "# check your work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Formatting & Normalization ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simple feature scaling\n",
    "    - new value = old value divided by max value\n",
    "    - df['col_name'] = df['col_name'] = df['col_name'] / df['col_name'].max()\n",
    "\n",
    "- min-max\n",
    "    - new value = old value - min value divided by max value minus min value\n",
    "    - df['col_name'] = (df['col_name'] - df['len'].mean()) / df['col_name'].std()\n",
    "\n",
    "\n",
    "- zscore\n",
    "    - new value = old value minus average divided by standard deviation\n",
    "\n",
    "- Data Normalization\n",
    "    - df['attribute_name'] = df['attribute_name']/df['attribute_name'].max()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning ###\n",
    "\n",
    "- create n number of grups of low, med, high, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(min(df['col_name'], max(df['col_name']), 4))\n",
    "df['col_binned'] = pd.cut(df['col'], bins, labels = 'group_names', include_lowest = True)\n",
    "\n",
    "#Binning\n",
    "bins = np.linspace(min(df['attribute_name']), max(df['attribute_name'],n))  # n is the number of bins needed \n",
    "GroupNames = ['Group1','Group2','Group3',...]\n",
    "df['binned_attribute_name'] = pd.cut(df['attribute_name'], bins, labels=GroupNames, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace missing data with frequency\n",
    "MostFrequentEntry = df['attribute_name'].value_counts().idxmax() \n",
    "df['attribute_name'].replace(np.nan,MostFrequentEntry, df['attribute_name'].replace(np.nan,MostFrequentEntry, inplace=True))\n",
    "\n",
    "#Replace missing data with mean\n",
    "AverageValue=df['attribute_name'].astype('data_type').mean(axis=0)\n",
    "df['attribute_name'].replace(np.nan, AverageValue, inplace=True)\n",
    "\n",
    "#Fix the data types\n",
    "df[['attribute1_name', 'attribute2_name', ...]] = df[['attribute1_name', 'attribute2_name', ...]].astype('data_type')\n",
    "\n",
    "#data_type is int, float, char, etc. \n",
    "\n",
    "#Change column name\n",
    "df.rename(columns={'old_name': 'new_name'}, inplace=True)\n",
    "\n",
    "#Indicator Variables\n",
    "dummy_variable = pd.get_dummies(df['attribute_name'])\n",
    "df = pd.concat([df, dummy_variable],axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts()\n",
    "\n",
    "col_counts = df = df['col'].value_counts()\n",
    "col_counts.rename(columns = {'col' : 'value_counts'}, inplace = True)\n",
    "col_counts.indexnon = 'col_name'\n",
    "\n",
    "#Group By\n",
    "df.groupby()\n",
    "df_test = df[['col1', 'col2', 'col3']]\n",
    "df_grp = df_test.groupby(['col1'], ['col2'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODULE 3 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Libraries\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Line Plot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x is independent variable and y is dependent  variable\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x,bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x,height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolor(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborne Functions ###\n",
    "\n",
    "- Regression Plot\n",
    "    - plot draws a scatter plot of two variables, x and y, and then fits the regression model and plots the \n",
    "    - resulting regression line along with a 95% confidence interval for that regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = 'header_1',y = 'header_2',data= df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box and whisker plot ### \n",
    " - shows the distribution of quantitative data in a way that facilitates comparisons between variables or across levels of a categorical variable. The box shows the quartiles of the dataset while the whiskers extend to show the rest of the distribution, except for points that are determined to be \"outliers\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Plot ### \n",
    "- Used to display the quality of polynomial regression. This function will regress y on x as a polynomial regression and then draw a scatterplot of the residuals.\n",
    "- Residuals are the differences between the observed values of the dependent variable and the predicted values obtained from the regression model. In other words, a residual is a measure of how much a regression line vertically misses a data point, meaning how far off the predictions are from the actual data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(data=df,x='header_1', y='header_2')\n",
    "#sns.residplot(x=df['header_1'], y=df['header_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KDE plot ### \n",
    "- A Kernel Density Estimate (KDE) plot is a graph that creates a probability distribution curve for the data based upon its likelihood of occurrence on a specific value. This is created for a single vector of information. It is used in the course in order to compare the likely curves of the actual data with that of the predicted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Plot ### \n",
    "- s plot has the capacity to combine the histogram and the KDE plots. \n",
    "- This plot creates the distribution curve using the bins of the histogram as a reference for estimation.\n",
    "- You can optionally keep or discard the histogram from being displayed. \n",
    "      - can be used interchangeably with the KDE plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sns.distplot(X,hist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helpful links\n",
    "\n",
    "https://www.geeksforgeeks.org/python-pandas-dataframe-to_string/\n",
    "\n",
    "https://stackoverflow.com/questions/39173813/pandas-convert-dtype-object-to-int"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
