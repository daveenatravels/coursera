{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODULE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " -Scientific Computing\n",
    "    >Pandas : Data Structures & Tools ~ Data manipulation & Analytics\n",
    "    >NumPy : Arrays & Matrices ~ all for data processing (can be used on obj\n",
    "    >SciPy : Integrals, Differentaial Equations, Optimization\n",
    "    \n",
    "-Visualization Libraries\n",
    "    >MatPlotLib : Plots and graphs\n",
    "    >Seaborn : plots: heatmaps, time series, violin plots)\n",
    "\n",
    "-Algorithmic Libraries (machine learning)\n",
    "    >scikit learn : statistical madeling, regression, classification, etc\n",
    "    >Statisical Models : explore data, estimate statistical models and perfrom tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Types                     Pandas              Python\n",
    "numbers and strings             object              string\n",
    "numeric characters              int64               int\n",
    "numeric characters w/decimal    float64             float\n",
    "time data                       datetime64          datetime module\n",
    "                                time delta[ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "url = file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/laptop_pricing_dataset_base.csv\"\n",
    "\n",
    "df = pd.read_csv(url, header=None)\n",
    "##df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulating Data Frames\n",
    "\n",
    "df['rawheader'] = df['rawheader'] +1\n",
    "\n",
    "missing  values\n",
    "    replace it with the average/mode if possible\n",
    "    drop the value/missing value;     df.dropna()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = ['price'], axis=0)  #drop row\n",
    "\n",
    "df.dropna(subset = ['price'], axis=1)  #drop column\n",
    "\n",
    "df.dropna(subset = ['price'], axis=0), inplace = True  #acts directly on data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace w/ new value\n",
    "\n",
    "df.replace('missing_value', 'new_value')\n",
    "mean = df['co_name'].mean()\n",
    "df['col_name'].replace(np.nan, mean)\n",
    "\n",
    "#Replace missing data with frequency\n",
    "MostFrequentEntry = df['attribute_name'].value_counts().idxmax() \n",
    "df['attribute_name'].replace(np.nan,MostFrequentEntry, df['attribute_name'].replace(np.nan,MostFrequentEntry, inplace=True))\n",
    "\n",
    "#Replace missing data with mean\n",
    "AverageValue=df['attribute_name'].astype('data_type').mean(axis=0)\n",
    "df['attribute_name'].replace(np.nan, AverageValue, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unit conversion\n",
    "df['miles'] = 235/ df['miles']\n",
    "df.rename(columns = { 'city_mpg' : 'city_L/100km'}, inplace=True)\n",
    "\n",
    "#correct data type\n",
    "df.astype()\n",
    "df['col_name'] = df['price'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple feature scaling\n",
    "  ##new value = old value divided by max value\n",
    "  df['col_name'] = df['col_name'] = df['col_name'] / df['col_name'].max()\n",
    "\n",
    "#min-max\n",
    "  ##new value = old value - min value divided by max value minus min value\n",
    "  df['col_name'] = (df['col_name'] - df['len'].mean()) / df['col_name'].std()\n",
    "\n",
    "\n",
    "#zscore\n",
    "  ##new value = old value minus average divided by standard deviation\n",
    "\n",
    "#Data Normalization\n",
    "df['attribute_name'] = df['attribute_name']/df['attribute_name'].max()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BINNING\n",
    "\n",
    "create n number of grups of low, med, high, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(min(df['col_name'], max(df['col_name']), 4))\n",
    "df['col_binned'] = pd.cut(df['col'], bins, labels = 'group_names', include_lowest = True)\n",
    "\n",
    "#Binning\n",
    "bins = np.linspace(min(df['attribute_name']), max(df['attribute_name'],n)  # n is the number of bins needed \n",
    "GroupNames = ['Group1','Group2','Group3,...]\n",
    "df['binned_attribute_name'] = \n",
    "pd.cut(df['attribute_name'], bins, labels=GroupNames, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace missing data with frequency\n",
    "MostFrequentEntry = df['attribute_name'].value_counts().idxmax() \n",
    "df['attribute_name'].replace(np.nan,MostFrequentEntry, df['attribute_name'].replace(np.nan,MostFrequentEntry, inplace=True))\n",
    "\n",
    "#Replace missing data with mean\n",
    "AverageValue=df['attribute_name'].astype('data_type').mean(axis=0)\n",
    "df['attribute_name'].replace(np.nan, AverageValue, inplace=True)\n",
    "\n",
    "#Fix the data types\n",
    "df[['attribute1_name', 'attribute2_name', ...]] = df[['attribute1_name', 'attribute2_name', ...]].astype('data_type')\n",
    "\n",
    "#data_type is int, float, char, etc. \n",
    "\n",
    "#Change column name\n",
    "df.rename(columns={'old_name': 'new_name'}, inplace=True)\n",
    "\n",
    "#Indicator Variables\n",
    "dummy_variable = pd.get_dummies(df['attribute_name'])\n",
    "df = pd.concat([df, dummy_variable],axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts()\n",
    "\n",
    "col_counts = df = df['col'].value_counts()\n",
    "col_counts.rename(columns = {'col' : 'value_counts'}, inplace = True)\n",
    "col_counts.indexnon = 'col_name'\n",
    "\n",
    "#Group By\n",
    "df.groupby()\n",
    "df_test = df[['col1', 'col2', 'col3']]\n",
    "df_grp = df_test.groupby(['col1'], ['col2'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Libraries\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Line Plot\n",
    "    ## x is independent variable and y is dependent  variable\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x,bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x,height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolor(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborne Functions\n",
    "\n",
    "Regression Plot\n",
    " plot draws a scatter plot of two variables, x and y, and then fits the regression model and plots the resulting regression line along with a 95% confidence interval for that regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = 'header_1',y = 'header_2',data= df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box and whisker plot\n",
    "shows the distribution of quantitative data in a way that facilitates comparisons between variables or across levels of a categorical variable. The box shows the quartiles of the dataset while the whiskers extend to show the rest of the distribution, except for points that are determined to be \"outliers\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual Plot\n",
    "used to display the quality of polynomial regression. This function will regress y on x as a polynomial regression and then draw a scatterplot of the residuals.\n",
    "Residuals are the differences between the observed values of the dependent variable and the predicted values obtained from the regression model. In other words, a residual is a measure of how much a regression line vertically misses a data point, meaning how far off the predictions are from the actual data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(data=df,x='header_1', y='header_2')\n",
    "#sns.residplot(x=df['header_1'], y=df['header_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KDE plot\n",
    "A Kernel Density Estimate (KDE) plot is a graph that creates a probability distribution curve for the data based upon its likelihood of occurrence on a specific value. This is created for a single vector of information. It is used in the course in order to compare the likely curves of the actual data with that of the predicted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution Plot\n",
    "s plot has the capacity to combine the histogram and the KDE plots. This plot creates the distribution curve using the bins of the histogram as a reference for estimation. You can optionally keep or discard the histogram from being displayed. In the context of the course, this plot can be used interchangeably with the KDE plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sns.distplot(X,hist=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
