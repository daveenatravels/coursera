{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODULE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " -Scientific Computing\n",
    "    >Pandas : Data Structures & Tools ~ Data manipulation & Analytics\n",
    "    >NumPy : Arrays & Matrices ~ all for data processing (can be used on obj\n",
    "    >SciPy : Integrals, Differentaial Equations, Optimization\n",
    "    \n",
    "-Visualization Libraries\n",
    "    >MatPlotLib : Plots and graphs\n",
    "    >Seaborn : plots: heatmaps, time series, violin plots)\n",
    "\n",
    "-Algorithmic Libraries (machine learning)\n",
    "    >scikit learn : statistical madeling, regression, classification, etc\n",
    "    >Statisical Models : explore data, estimate statistical models and perfrom tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Types                     Pandas              Python\n",
    "numbers and strings             object              string\n",
    "numeric characters              int64               int\n",
    "numeric characters w/decimal    float64             float\n",
    "time data                       datetime64          datetime module\n",
    "                                time delta[ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "url = file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/laptop_pricing_dataset_base.csv\"\n",
    "\n",
    "df = pd.read_csv(url, header=None)\n",
    "##df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulating Data Frames\n",
    "\n",
    "df['rawheader'] = df['rawheader'] +1\n",
    "\n",
    "missing  values\n",
    "    replace it with the average/mode if possible\n",
    "    drop the value/missing value;     df.dropna()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = ['price'], axis=0)  #drop row\n",
    "\n",
    "df.dropna(subset = ['price'], axis=1)  #drop column\n",
    "\n",
    "df.dropna(subset = ['price'], axis=0), inplace = True  #acts directly on data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace w/ new value\n",
    "\n",
    "df.replace('missing_value', 'new_value')\n",
    "mean = df['co_name'].mean()\n",
    "df['col_name'].replace(np.nan, mean)\n",
    "\n",
    "#Replace missing data with frequency\n",
    "MostFrequentEntry = df['attribute_name'].value_counts().idxmax() \n",
    "df['attribute_name'].replace(np.nan,MostFrequentEntry, df['attribute_name'].replace(np.nan,MostFrequentEntry, inplace=True))\n",
    "\n",
    "#Replace missing data with mean\n",
    "AverageValue=df['attribute_name'].astype('data_type').mean(axis=0)\n",
    "df['attribute_name'].replace(np.nan, AverageValue, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unit conversion\n",
    "df['miles'] = 235/ df['miles']\n",
    "df.rename(columns = { 'city_mpg' : 'city_L/100km'}, inplace=True)\n",
    "\n",
    "#correct data type\n",
    "df.astype()\n",
    "df['col_name'] = df['price'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple feature scaling\n",
    "  ##new value = old value divided by max value\n",
    "  df['col_name'] = df['col_name'] = df['col_name'] / df['col_name'].max()\n",
    "\n",
    "#min-max\n",
    "  ##new value = old value - min value divided by max value minus min value\n",
    "  df['col_name'] = (df['col_name'] - df['len'].mean()) / df['col_name'].std()\n",
    "\n",
    "\n",
    "#zscore\n",
    "  ##new value = old value minus average divided by standard deviation\n",
    "\n",
    "#Data Normalization\n",
    "df['attribute_name'] = df['attribute_name']/df['attribute_name'].max()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BINNING\n",
    "\n",
    "create n number of grups of low, med, high, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(min(df['col_name'], max(df['col_name']), 4))\n",
    "df['col_binned'] = pd.cut(df['col'], bins, labels = 'group_names', include_lowest = True)\n",
    "\n",
    "#Binning\n",
    "bins = np.linspace(min(df['attribute_name']), max(df['attribute_name'],n)  # n is the number of bins needed \n",
    "GroupNames = ['Group1','Group2','Group3,...]\n",
    "df['binned_attribute_name'] = \n",
    "pd.cut(df['attribute_name'], bins, labels=GroupNames, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace missing data with frequency\n",
    "MostFrequentEntry = df['attribute_name'].value_counts().idxmax() \n",
    "df['attribute_name'].replace(np.nan,MostFrequentEntry, df['attribute_name'].replace(np.nan,MostFrequentEntry, inplace=True))\n",
    "\n",
    "#Replace missing data with mean\n",
    "AverageValue=df['attribute_name'].astype(<data_type>).mean(axis=0)\n",
    "df['attribute_name'].replace(np.nan, AverageValue, inplace=True)\n",
    "\n",
    "#Fix the data types\n",
    "df[['attribute1_name', 'attribute2_name', ...]] = \n",
    "df[['attribute1_name', 'attribute2_name', ...]].astype('data_type')\n",
    "\n",
    "#data_type is int, float, char, etc. \n",
    "\n",
    "#Change column name\n",
    "df.rename(columns={'old_name': 'new_name'}, inplace=True)\n",
    "\n",
    "#Indicator Variables\n",
    "dummy_variable = pd.get_dummies(df['attribute_name'])\n",
    "df = pd.concat([df, dummy_variable],axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts()\n",
    "\n",
    "col_counts = df = df['col'].value_counts()\n",
    "col_counts.rename(columns = {'col' : 'value_counts'}, inplace = True)\n",
    "col_counts.indexnon = 'col_name'\n",
    "\n",
    "#Group By\n",
    "df.groupby()\n",
    "df_test = df[['col1', 'col2', 'col3']]\n",
    "df_grp = df_test.groupby(['col1'], ['col2'], as_index = False).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
